{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXJxkc2_AguP"
   },
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V4oseuDC80YX",
    "outputId": "0db91101-d019-4672-bfdb-2cbd4496ab6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "train = './train.zip'\n",
    "\n",
    "with ZipFile(train, 'r') as zip:\n",
    "  zip.extractall()\n",
    "  print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OJcrkqCl80DR",
    "outputId": "1a84c435-1b2b-4a6d-bc4a-e8b190af8dad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "test = './test.zip'\n",
    "\n",
    "with ZipFile(test, 'r') as zip:\n",
    "  zip.extractall()\n",
    "  print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "M0hobcehCRlp",
    "ExecuteTime": {
     "end_time": "2023-11-30T06:55:19.106645700Z",
     "start_time": "2023-11-30T06:55:19.086648900Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AAJ0zUpdAm98"
   },
   "source": [
    "# Data preprossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "saI77vxKAy2A",
    "ExecuteTime": {
     "end_time": "2023-11-30T06:55:21.131338800Z",
     "start_time": "2023-11-30T06:55:21.112301500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QQUDF5efAyrx",
    "ExecuteTime": {
     "end_time": "2023-11-30T06:55:23.089888600Z",
     "start_time": "2023-11-30T06:55:23.073897200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "train_dir = './dataset_slova/train'\n",
    "test_dir = './dataset_slova/test'\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "AAT7z4QpC4WU",
    "ExecuteTime": {
     "end_time": "2023-11-30T06:55:25.374741700Z",
     "start_time": "2023-11-30T06:55:25.353413800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = ImageFolder(test_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wauxgc0_AwGI"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "inab5UGx0uVU",
    "ExecuteTime": {
     "end_time": "2023-11-30T06:55:31.818564800Z",
     "start_time": "2023-11-30T06:55:31.772896600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237 50\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 16\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "image_width = 475\n",
    "image_height = 100\n",
    "# Convolutional layer parameters\n",
    "kernel_size = 3\n",
    "stride = 1\n",
    "padding = 1\n",
    "channels = 32\n",
    "\n",
    "# Calculate output size after convolutional layer\n",
    "conv_output_width = math.floor((image_width - kernel_size + 2 * padding) / stride) + 1\n",
    "conv_output_height = math.floor((image_height - kernel_size + 2 * padding) / stride) + 1\n",
    "\n",
    "# Calculate output size after max pooling layer\n",
    "pool_output_width = math.floor(conv_output_width / 2)\n",
    "pool_output_height = math.floor(conv_output_height / 2)\n",
    "print(pool_output_width, pool_output_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xadS7gBN30zV",
    "ExecuteTime": {
     "end_time": "2023-11-30T06:59:39.329898700Z",
     "start_time": "2023-11-30T06:59:39.321866500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9DbL8mnRVJSG",
    "ExecuteTime": {
     "end_time": "2023-11-30T06:59:43.033530600Z",
     "start_time": "2023-11-30T06:59:43.010492400Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(pool_output_width * pool_output_height * channels, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = x.view(-1, pool_output_width * pool_output_height * channels)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tg-y_3QAlZdO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "18obzU3WVJN6",
    "ExecuteTime": {
     "end_time": "2023-11-30T06:59:47.467339300Z",
     "start_time": "2023-11-30T06:59:47.145713300Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zjHs--fOVJJ5",
    "ExecuteTime": {
     "end_time": "2023-11-30T07:00:05.739756800Z",
     "start_time": "2023-11-30T07:00:05.713690700Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion):\n",
    "    train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        #print(outputs.shape)\n",
    "        outputs = torch.squeeze(outputs)\n",
    "        #print(outputs.shape)\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()*inputs.size(0)\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            #print(outputs.shape)\n",
    "            outputs = torch.squeeze(outputs)\n",
    "            #print(outputs.shape)\n",
    "            predicted = (outputs > 0).int()  # Convert logits to binary predictions\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    print(f'total: {total}, correct: {correct}')\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fii26uujrOae",
    "outputId": "f7434030-2b34-4f14-da77-c60469e2581a",
    "ExecuteTime": {
     "end_time": "2023-11-30T07:05:18.613124400Z",
     "start_time": "2023-11-30T07:00:13.313535300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 240, correct: 163\n",
      "Epoch 1/10, Test Accuracy: 0.6792\n",
      "total: 240, correct: 192\n",
      "Epoch 2/10, Test Accuracy: 0.8000\n",
      "total: 240, correct: 202\n",
      "Epoch 3/10, Test Accuracy: 0.8417\n",
      "total: 240, correct: 191\n",
      "Epoch 4/10, Test Accuracy: 0.7958\n",
      "total: 240, correct: 211\n",
      "Epoch 5/10, Test Accuracy: 0.8792\n",
      "total: 240, correct: 199\n",
      "Epoch 6/10, Test Accuracy: 0.8292\n",
      "total: 240, correct: 202\n",
      "Epoch 7/10, Test Accuracy: 0.8417\n",
      "total: 240, correct: 209\n",
      "Epoch 8/10, Test Accuracy: 0.8708\n",
      "total: 240, correct: 209\n",
      "Epoch 9/10, Test Accuracy: 0.8708\n",
      "total: 240, correct: 212\n",
      "Epoch 10/10, Test Accuracy: 0.8833\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)\n",
    "    accuracy = evaluate(model, test_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'binary_classifier_cnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qzlMA89FVI2T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R0VZ4C8hUSry"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
